MCPサーバー設計仕様書文書バージョン: 1.0作成日: 2025年7月28日作成者: Gemini1. 概要 (Overview)本ドキュメントは、LLM（大規模言語モデル）を活用したAIエージェントにおける、長期的な対話一貫性を維持するためのMCP（Management and Control Plane）サーバーの設計仕様を定義する。LLMは、長い対話や複数ターンにわたるやり取りの中で、初期の目的や重要な制約条件を「忘れてしまう」という課題を抱える。本MCPサーバーは、ユーザーアプリケーションとLLMの間に位置し、対話の文脈をインテリジェントに分析・管理・再構築することでこの問題を解決する。2. 目的とスコープ (Objectives and Scope)2.1. 目的長期的な対話において、AIエージェントが対話の核となる目的を見失わないようにする。対話の中で追加された重要な制約や決定事項を一貫して記憶・適用させる。上記を通じて、ユーザーの真の課題解決に焦点を合わせ続けた、信頼性の高いAIエージェントを実現する。2.2. スコープ本設計書のスコープは、MCPサーバーのバックエンドロジックに限定される。ユーザーインターフェース（UI）や、LLMモデル自体の開発はスコープ外とする。3. 全体アーキテクチャ (Overall Architecture)MCPサーバーは、アプリケーションとLLM APIの中間に位置するプロキシとして動作する。[クライアントアプリケーション] <------> [MCPサーバー] <------> [LLM API]
すべてのリクエストとレスポンスはMCPサーバーを経由し、MCPサーバーがコンテキスト管理の責務を担う。4. 主要コンポーネント詳細設計 (Detailed Component Design)4.1. インテリジェント・インテント分類器 (Intelligent Intent Classifier)ユーザーからの各発言の「意図」を分類するコンポーネント。LLMの分類能力を活用する。入力: ユーザーからの生のテキストメッセージ。処理: 事前に定義された分類用プロンプト（付録Aを参照）を用いて、軽量・高速なLLMモデルにAPIリクエストを送信する。出力: 以下の構造を持つJSONオブジェクト。{
  "intent": ["LABEL_1", "LABEL_2"],
  "reason": "分類理由のテキスト"
}
定義済みラベル:PROBLEM_DEFINITION: ユーザーが解決したい中心的な課題を定義している。CONSTRAINT_ADDITION: 予算、期間などの制約や条件を追加している。REFINEMENT: 既存の要求をより具体的に、または修正している。QUESTION: 単純な質問をしている。UNCLEAR: 上記のいずれにも明確に分類できない。4.2. 階層型コンテキストストア (Hierarchical Context Store)分類されたコンテキストを、その重要度に応じて3階層のメモリに格納する。Core Context (長期記憶):格納条件: インテントがPROBLEM_DEFINITIONと判定された発言。通常、対話セッションで一度だけ設定される。データ: 発言の生テキスト。役割: 対話の目的を保持する。Evolving Context (中期記憶):格納条件: インテントがCONSTRAINT_ADDITIONまたはREFINEMENTと判定された発言。データ: 決定事項や制約事項を簡潔にまとめたテキストのリスト。役割: 対話のルールや条件を保持する。Turn Context (短期記憶):格納条件: 直近の2〜3回の対話履歴。データ: 発言の生テキスト。役割: 自然な会話の流れを維持する。4.3. プロンプト合成エンジン (Prompt Synthesis Engine)主応答を生成するLLMにリクエストを送信する直前に、階層型コンテキストストアから情報を取り出し、最終的なプロンプトを動的に構築する。プロンプトテンプレート:# Mission (あなたの使命)
あなたはユーザーの課題解決を支援するAIアシスタントです。以下の核となる目的を常に念頭に置いてください。
{Core Contextの内容を挿入}

# Constraints (遵守すべき制約と決定事項)
以下の条件を必ず満たすように応答を生成してください。
- {Evolving Contextのリスト項目を挿入}
- {Evolving Contextのリスト項目を挿入}

# Recent Conversation (直近の会話)
{Turn Contextの内容を挿入}

# User's Current Message (ユーザーの現在のメッセージ)
{ユーザーの最新のメッセージを挿入}
5. データフロー (Data Flow)ユーザーからの1回のメッセージは、以下のシーケンスで処理される。[受信]: MCPサーバーがクライアントアプリケーションからユーザーメッセージを受信する。[分類]: インテント分類器がメッセージの意図を分析し、JSON形式で結果を出力する。[格納]: 分類結果に基づき、メッセージを階層型コンテキストストアの適切な階層（Core, Evolving, Turn）に格納する。[合成]: プロンプト合成エンジンが、コンテキストストアの全階層から最新の情報を取り出し、最終的なプロンプトを構築する。[実行]: 合成されたプロンプトを、主応答生成用の高性能LLM APIに送信する。[返信]: LLMからの応答をクライアントアプリケーションに返す。6. 実装上の考慮事項 (Implementation Considerations)技術スタック例:サーバーフレームワーク: Python (FastAPI, Flaskなど)HTTPクライアント: requests, httpxモデル選択:インテント分類器: GPT-3.5-Turbo, Gemini 1.5 Flash, Claude 3 Haikuなど、軽量・高速・安価なモデルを推奨。主応答生成: GPT-4o, Gemini 1.5 Pro, Claude 3 Opusなど、高性能なモデルを推奨。APIパラメータ設定:インテント分類器: temperatureは0.1以下の低い値に設定し、出力の安定性を確保する。APIが対応している場合はJSONモードを有効化する。主応答生成: タスクに応じて適切なtemperatureを設定する（例: 創造性が必要なら0.7、正確性が必要なら0.2）。付録A: インテント分類器用プロンプトテンプレート# 命令
あなたは、ユーザーの発言の「意図」を分析する専門家です。以下の手順に従って、ユーザー発言を分析し、結果をJSON形式で出力してください。

# 手順
1. ユーザー発言を注意深く読み、その発言が何を目的としているかを分析します。
2. 分析した結果、最も合致する意図ラベルを下記の「ラベル定義」から選択します。意図が複数含まれる場合は、リスト形式で最大2つまで選択してください。
3. なぜそのラベルを選択したのか、理由を簡潔に記述します。
4. 最終的な結果を、指定されたJSON形式で出力します。

# ラベル定義
- PROBLEM_DEFINITION: ユーザーが解決したい中心的な課題を定義している。
- CONSTRAINT_ADDITION: 予算、期間などの制約や条件を追加している。
- REFINEMENT: 既存の要求をより具体的に、または修正している。
- QUESTION: 単純な質問をしている。
- UNCLEAR: 上記のいずれにも明確に分類できない。

# お手本 (Examples)
- 発言: 「AIで議事録を自動要約したいんだけど、何かいい方法ある？」
  - JSON: {"intent": ["PROBLEM_DEFINITION", "QUESTION"], "reason": "ユーザーは『議事録の自動要約』という中心課題を提示し、同時に質問している。"}
- 発言: 「いいね。ただし、利用するモデルはオープンソースのものに限定してほしい。」
  - JSON: {"intent": ["CONSTRAINT_ADDITION"], "reason": "『オープンソースに限定』という明確な制約を追加している。"}

# 分析対象
ユーザー発言: """
{ここにユーザーの実際のメッセージを挿入}
"""

# 出力フォーマット
{"intent": [String], "reason": String}

# 出力
