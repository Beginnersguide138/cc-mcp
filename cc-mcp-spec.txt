CC-MCPサーバー設計仕様書
文書バージョン: 1.3
作成日: 2025年7月28日
変更点: v1.2に対し、MCPサーバーの役割を明確化するセクションを追加。
1. 概要 (Overview)
1.1. 基本概要
本ドキュメントは、LLM（大規模言語モデル）を活用したAIエージェントにおける、長期的な対話一貫性を維持するためのMCP（Management and Control Plane）サーバーの設計仕様を定義する。
LLMは、長い対話や複数ターンにわたるやり取りの中で、初期の目的や重要な制約条件を「忘れてしまう」という課題を抱える。本MCPサーバーは、ユーザーアプリケーションとLLMの間に位置し、対話の文脈をインテリジェントに分析・管理・再構築することでこの問題を解決する。
1.2. 役割の明確化 (Clarification of Roles) - (重要)
本MCPサーバーは、ユーザーに対する最終的な応答テキストを生成しません。 その主要な役割は、対話の文脈を分析・管理し、最終応答を生成する外部の高性能LLMのための**「最適化されたプロンプトを合成する」**ことに特化しています。
MCPサーバーの責務: コンテキスト分析、状態管理、プロンプト合成（司令塔・秘書役）
外部LLMの責務: MCPサーバーから受け取ったプロンプトに基づき、高品質な最終応答を生成（実行役）
この役割分担により、各コンポーネントが自身の得意な処理に専念し、システム全体のパフォーマンスと信頼性を最大化します。
2. 目的とスコープ (Objectives and Scope)
2.1. 目的
長期的な対話において、AIエージェントが対話の核となる目的を見失わないようにする。
対話の中で追加された重要な制約や決定事項を一貫して記憶・適用させる。
上記を通じて、ユーザーの真の課題解決に焦点を合わせ続けた、信頼性の高いAIエージェントを実現する。
2.2. スコープ
本設計書のスコープは、MCPサーバーのバックエンドロジックに限定される。
ユーザーインターフェース（UI）や、LLMモデル自体の開発はスコープ外とする。
3. 全体アーキテクチャ (Overall Architecture)
MCPサーバーは、アプリケーションと主応答生成用の高性能LLM APIの中間に位置するステートフルなプロキシとして動作する。クライアントは、セッションIDを用いて対話の継続性を担保する。このアーキテクチャは、処理の責務を明確に分離する。
// 1. セッション開始
[クライアント] --(Start Session)--> [MCPサーバー]
             <--(session_id)-----

// 2. 対話の継続
[クライアント] --(session_id, new_message)--> [MCPサーバー]
             <--(ai_response)-----------------


4. 主要コンポーネント詳細設計 (Detailed Component Design)
4.1. セッションマネージャー (Session Manager)
役割: 各対話セッションを一意に識別し、セッションごとのコンテキストストアを管理する。
機能:
start_session(): 新規セッションを開始し、ユニークなsession_idを発行する。同時に、そのセッションIDに紐づく空の「階層型コンテキストストア」をサーバー内に生成・保持する。
get_context(session_id): 指定されたsession_idに対応するコンテキストストアを取得する。
end_session(session_id): セッションを終了し、関連するコンテキストストアを破棄する。
4.2. インテリジェント・インテント分類器 (Intelligent Intent Classifier)
役割: 現在のターンで受信した単一のユーザーメッセージのみを分析対象とし、その「意図」を分類する。
出力: 以下の構造を持つJSONオブジェクト。
{
  "intent": ["LABEL_1", "LABEL_2"],
  "reason": "分類理由のテキスト"
}


定義済みラベル:
PROBLEM_DEFINITION: ユーザーが解決したい中心的な課題を定義している。
CONSTRAINT_ADDITION: 予算、期間などの制約や条件を追加している。
REFINEMENT: 既存の要求をより具体的に、または修正している。
QUESTION: 単純な質問をしている。
UNCLEAR: 上記のいずれにも明確に分類できない。
4.3. キーワード抽出エンジン (Keyword Extraction Engine)
役割: 対話の重要なターンから、その内容を象徴するキーワードを統計的に抽出する。これにより、コンテキストの検索性と要約性を高める。
技術: TF-IDF (Term Frequency-Inverse Document Frequency)
TF (単語の出現頻度): 各ターンのメッセージ内での単語の出現頻度。
IDF (逆文書頻度): 全対話セッションの全メッセージをコーパスとし、単語の希少性を計算する。
実行タイミング: インテントが PROBLEM_DEFINITION, CONSTRAINT_ADDITION, REFINEMENT と判定されたメッセージに対して実行される。
4.4. 階層型コンテキストストア (Hierarchical Context Store)
役割: MCPサーバー内のセッションマネージャーによって、セッションIDごとに管理される。
階層:
Core Context (長期記憶): インテントがPROBLEM_DEFINITIONと判定された発言と、抽出されたキーワードを格納。
Evolving Context (中期記憶): インテントがCONSTRAINT_ADDITIONまたはREFINEMENTと判定された発言と、抽出されたキーワードを格納。
Turn Context (短期記憶): 直近の2〜3回の対話履歴（ユーザーとAI双方）を格納。
4.5. プロンプト合成エンジン (Prompt Synthesis Engine)
役割: session_idをキーとして現在のセッションに紐づく完全なコンテキストストアを取得し、主応答生成用のプロンプトを動的に構築する。
プロンプトテンプレート:
# Mission (あなたの使命)
あなたはユーザーの課題解決を支援するAIアシスタントです。以下の核となる目的を常に念頭に置いてください。
{Core Contextの内容を挿入}

# Constraints (遵守すべき制約と決定事項)
以下の条件を必ず満たすように応答を生成してください。
- {Evolving Contextのリスト項目を挿入}

# Recent Conversation (直近の会話)
{Turn Contextの内容を挿入}

# User's Current Message (ユーザーの現在のメッセージ)
{ユーザーの最新のメッセージを挿入}


5. データフロー (Data Flow)
5.1. セッション開始
[要求]: クライアントがMCPサーバーにセッション開始を要求する。
[生成]: セッションマネージャーがユニークなsession_idと、それに紐づく空のコンテキストストアを生成する。
[返信]: session_idをクライアントに返す。
5.2. 対話ターン処理
[受信]: MCPサーバーがクライアントからsession_idと新しいユーザーメッセージを受信する。
[取得]: セッションマネージャーがsession_idを基に、対応するコンテキストストアを取得する。
[分類]: インテント分類器が新しいユーザーメッセージのみを分析し、意図を分類する。
[更新と抽出]:
a. 分類結果に基づき、取得したコンテキストストアの内容を更新する。
b. もしインテントが重要（PROBLEM_DEFINITIONなど）であれば、キーワード抽出エンジンがキーワードを抽出し、メタデータとして保存する。
[合成]: プロンプト合成エンジンが、更新された完全なコンテキストストアを使用して、主応答生成用のプロンプトを構築する。
[実行]: 合成されたプロンプトを高性能LLM APIに送信する。
[格納]: LLMからの応答を、Turn Contextに格納する。
[返信]: LLMからの応答をクライアントに返す。
6. 実装上の考慮事項 (Implementation Considerations)
技術スタック例:
サーバーフレームワーク: Python (FastAPI, Flaskなど)
HTTPクライアント: requests, httpx
モデル選択:
インテント分類器: GPT-3.5-Turbo, Gemini 1.5 Flash, Claude 3 Haikuなど、軽量・高速・安価なモデルを推奨。
主応答生成: GPT-4o, Gemini 1.5 Pro, Claude 3 Opusなど、高性能なモデルを推奨。
APIパラメータ設定:
インテント分類器: temperatureは0.1以下の低い値に設定し、出力の安定性を確保する。APIが対応している場合はJSONモードを有効化する。
主応答生成: タスクに応じて適切なtemperatureを設定する。
付録A: インテント分類器用プロンプトテンプレート
# 命令
あなたは、ユーザーの発言の「意図」を分析する専門家です。以下の手順に従って、ユーザー発言を分析し、結果をJSON形式で出力してください。

# 手順
1. ユーザー発言を注意深く読み、その発言が何を目的としているかを分析します。
2. 分析した結果、最も合致する意図ラベルを下記の「ラベル定義」から選択します。意図が複数含まれる場合は、リスト形式で最大2つまで選択してください。
3. なぜそのラベルを選択したのか、理由を簡潔に記述します。
4. 最終的な結果を、指定されたJSON形式で出力します。

# ラベル定義
- PROBLEM_DEFINITION: ユーザーが解決したい中心的な課題を定義している。
- CONSTRAINT_ADDITION: 予算、期間などの制約や条件を追加している。
- REFINEMENT: 既存の要求をより具体的に、または修正している。
- QUESTION: 単純な質問をしている。
- UNCLEAR: 上記のいずれにも明確に分類できない。

# お手本 (Examples)
- 発言: 「AIで議事録を自動要約したいんだけど、何かいい方法ある？」
  - JSON: {"intent": ["PROBLEM_DEFINITION", "QUESTION"], "reason": "ユーザーは『議事録の自動要約』という中心課題を提示し、同時に質問している。"}
- 発言: 「いいね。ただし、利用するモデルはオープンソースのものに限定してほしい。」
  - JSON: {"intent": ["CONSTRAINT_ADDITION"], "reason": "『オープンソースに限定』という明確な制約を追加している。"}

# 分析対象
ユーザー発言: """
{ここにユーザーの実際のメッセージを挿入}
"""

# 出力フォーマット
{"intent": [String], "reason": String}

# 出力


